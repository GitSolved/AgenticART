# ═══════════════════════════════════════════════════════════════════════════════
# LLM-AndroidPentest Configuration
# Copy to .env and fill in your values
# ═══════════════════════════════════════════════════════════════════════════════

# ─── LLM Provider Selection ─────────────────────────────────────────────────
# Active provider: ollama | openai | anthropic
LLM_PROVIDER=ollama

# ─── Ollama Configuration (Recommended - Local, Free, Private) ──────────────
# Install: https://ollama.ai/download
# List models: ollama list
# Pull model: ollama pull llama3.1:70b
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:70b-instruct-q4_K_M
OLLAMA_TEMPERATURE=0.7
OLLAMA_CONTEXT_LENGTH=8192

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ MODEL RECOMMENDATIONS (based on arxiv 2509.07933 research)                  │
# ├─────────────────────────────────────────────────────────────────────────────┤
# │ TIER 1 - Best Results (requires 48GB+ RAM or cloud API):                    │
# │   llama3.1:70b-instruct-q4_K_M - RECOMMENDED: Best for exploit generation   │
# │   deepseek-coder:33b           - Excellent code generation                  │
# │                                                                             │
# │ TIER 2 - Good Results (requires 16GB+ RAM):                                 │
# │   codellama:34b     - Strong code generation, good security understanding   │
# │   mixtral:8x7b      - Fast inference, decent reasoning                      │
# │                                                                             │
# │ TIER 3 - Basic/Testing (8GB RAM):                                           │
# │   llama3.1:8b       - REFUSES exploit generation (safety filters)           │
# │   codellama:7b      - Fast but struggles with complex attack chains         │
# │                                                                             │
# │ IMPORTANT: 8B models REFUSE exploit generation due to aggressive RLHF.      │
# │            Use 70B-instruct for full paper methodology.                     │
# └─────────────────────────────────────────────────────────────────────────────┘

# ─── NVD API Configuration (Live CVE Data) ─────────────────────────────────
# Get free API key: https://nvd.nist.gov/developers/request-an-api-key
# Without key: 5 requests/30 seconds | With key: 50 requests/30 seconds
NVD_API_KEY=

# ─── OpenAI Configuration (Optional) ────────────────────────────────────────
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4096

# ─── Anthropic Configuration (RECOMMENDED for best results) ────────────────
# Claude models exhibit superior penetration testing capabilities (2024 research)
# PentestGPT now uses Claude as primary model
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# ─── PentestGPT Integration ──────────────────────────────────────────────────
PENTESTGPT_MODE=api  # api | local | bridge
PENTESTGPT_ENDPOINT=

# ─── Android Emulator (Genymotion) ───────────────────────────────────────────
# macOS: /Applications/Genymotion.app
# Linux: /opt/genymotion or ~/genymotion
# Windows: C:\Program Files\Genymotion
GENYMOTION_PATH=
GENYMOTION_ADB_PATH=adb
EMULATOR_DEVICE=
EMULATOR_IP=192.168.56.101
EMULATOR_PORT=5555

# ─── Execution Settings ──────────────────────────────────────────────────────
AUTO_EXECUTE_SCRIPTS=false  # Safety: require confirmation before running
SCRIPT_TIMEOUT=300          # Seconds before script timeout
LOG_LEVEL=INFO              # DEBUG | INFO | WARNING | ERROR

# ─── Web Application ─────────────────────────────────────────────────────────
WEBAPP_HOST=127.0.0.1
WEBAPP_PORT=8501
WEBAPP_DEBUG=true
