# AgenticART: Android Red Team Training Dojo for Security LLMs

A research framework for training Large Language Models (LLMs) on Android security tasks through structured challenges, execution-verified feedback, and curriculum-based skill progression.

---

## Why AgenticART?

### The Problem

Most LLMs can *talk* about security but can't *do* security. They hallucinate commands, misunderstand Android internals, and fail when execution matters. Training data for security tasks is scarce, outdated, or synthetic.

### The Solution

AgenticART creates **AI agents that can actually perform security assessments** by:

- Training on **real CVEs** from Android Security Bulletins (not textbook examples)
- Using **execution-verified feedback** (did the command actually work?)
- Providing **structured progression** from beginner to advanced (belt system)

### Who Is This For?

AgenticART serves a specific audience:

| Audience | Why AgenticART? |
|----------|-----------------|
| **AI Security Researchers** | Study whether curriculum-based training improves security task performance. Benchmark before/after fine-tuning to validate the belt progression hypothesis. |
| **Air-Gapped Environments** | Organizations that cannot use cloud APIs (compliance, classification, regulatory). Train a local model once, deploy offline forever. |
| **Cost-Conscious Teams** | Cloud API costs add up. A fine-tuned 7B model running locally is free after initial training. |

### What Problem Does It Solve?

**GPT-4o can already do Android security tasks. Why bother?**

If you can use GPT-4o: Just use it. This framework won't beat frontier models.

If you *can't* use cloud APIs, you need a local model. But local models (7B-13B) are worse at security tasks. AgenticART provides:

1. **Execution-verified training data** - Not "GPT-4o said this might work" but "this command actually succeeded on a real device"
2. **Curriculum structure** - Progressive difficulty that (hypothesis) accelerates skill acquisition
3. **Benchmarking infrastructure** - Measure if your fine-tuned model actually improved

### The Testable Hypothesis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Does Belt Progression Work?                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. Benchmark base model (e.g., Llama 3.1 8B) on all 192        â”‚
â”‚     challenges. Record pass rate per belt.                       â”‚
â”‚                                                                  â”‚
â”‚  2. Fine-tune on execution-verified traces from Whiteâ†’Green      â”‚
â”‚     belt challenges.                                             â”‚
â”‚                                                                  â”‚
â”‚  3. Re-benchmark. Compare pass rates.                            â”‚
â”‚                                                                  â”‚
â”‚  If pass rate improves: Belt progression validated.              â”‚
â”‚  If no improvement: Approach needs revision.                     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is research infrastructure, not a finished product.

---

## How It Works

AgenticART implements a "Dojo" training system where AI agents learn Android vulnerability assessment through a continuous improvement loop:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AgenticART Architecture                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚   NVD    â”‚â”€â”€â”€â–¶â”‚ Challengeâ”‚â”€â”€â”€â–¶â”‚  Agent   â”‚â”€â”€â”€â–¶â”‚ Android  â”‚ â”‚
â”‚   â”‚   API    â”‚    â”‚ Generatorâ”‚    â”‚ Executor â”‚    â”‚ Emulator â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                          â”‚              â”‚       â”‚
â”‚                                          â–¼              â–¼       â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                   â”‚  Grader  â”‚â—€â”€â”€â”‚Exec Traceâ”‚  â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                          â”‚                      â”‚
â”‚                                          â–¼                      â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                                   â”‚ Training â”‚                  â”‚
â”‚                                   â”‚   Data   â”‚                  â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Loop:**
1. **Challenge Generation** - Pull real CVEs from NVD, classify by difficulty
2. **Agent Execution** - LLM attempts the challenge on a live Android device
3. **Grading** - Verify if the output achieved the objective
4. **Training Data** - Successful attempts become "gold" training examples
5. **Model Refinement** - Fine-tune models on verified execution traces
6. **Repeat** - Progressively harder challenges, continuously improving agents

---

## Curriculum Statistics

**Last Updated:** December 2025 (after value-based pruning)

| Belt | Challenges | Skill Level | Focus Area |
|------|------------|-------------|------------|
| White | 5 | Beginner | Device reconnaissance, basic ADB |
| Yellow | 11 | Novice | Information disclosure, simple DoS |
| Orange | 30 | Intermediate | Permission bypass, logic bugs |
| Green | 43 | Intermediate+ | IPC, content providers, intents |
| Blue | 24 | Advanced | Buffer overflows, high-severity EoP |
| Brown | 47 | Expert | UAF, race conditions, memory corruption |
| Purple | 16 | Elite | Qualcomm critical, RCE vectors |
| Black | 16 | Master | Kernel exploits, zero-click analysis |
| **Total** | **192** | | |

**CVE Sources:** NIST National Vulnerability Database, Android Security Bulletins (2019-2025)

*91 low-value challenges pruned using automated value scoring (see `scripts/evaluate_curriculum.py`)*

---

## Execution Capabilities & Design Choices

### What Agents CAN Do (Full Execution)

| Domain | Status | Description |
|--------|--------|-------------|
| **ADB/Shell** | âœ… Full | Device reconnaissance, package analysis, system probing |
| **Frida** | âœ… Full | Runtime hooking, API interception, memory inspection |
| **Content Providers** | âœ… Full | Query/exploit exposed data interfaces |
| **Intent Attacks** | âœ… Full | IPC manipulation, deep link exploitation |
| **Logcat Analysis** | âœ… Full | Sensitive data leakage detection |

### Intentional Constraints (Realistic Training)

#### ğŸ”’ Non-Rooted Environment (By Design)

**Why:** ~95% of real Android devices are NOT rooted. Training agents on rooted emulators would teach unrealistic techniques that fail in the real world.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              REALISTIC CONSTRAINT TRAINING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  âŒ If we trained on rooted emulators:                          â”‚
â”‚     Agent learns: "su -c cat /data/data/com.app/secrets.db"     â”‚
â”‚     Real world:   "su: not found" â†’ FAILS on 95% of devices     â”‚
â”‚                                                                  â”‚
â”‚  âœ… Current approach (non-rooted):                              â”‚
â”‚     Agent learns: Exploit logic bugs, misconfigurations         â”‚
â”‚     Agent learns: "run-as com.debuggable.app cat databases/*"   â”‚
â”‚     Agent learns: Chain low-privilege vulnerabilities           â”‚
â”‚     Real world:   Actually works on real targets                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Result:** Agents learn to hack like real attackers, not like someone who already owns the device.

#### âš ï¸ C/Native Code (Syntax Validation Only)

**Current State:** C exploit code is validated for syntax but NOT compiled or executed on device.

**Why this limitation exists:**
- Requires NDK cross-compilation (ARM toolchain)
- Binary must be pushed to device and executed
- Most native exploits target specific kernel versions/builds
- Not yet implemented (contribution welcome!)

**Impact:** Black/Purple belt kernel challenges are **detection-focused** - agents analyze vulnerabilities but cannot execute native exploits.

**Fixable?** Yes - NDK integration would enable full native execution. See [Contributing](#contributing).

#### ğŸ“± Emulator vs Physical Device

| Aspect | Emulator | Physical Device |
|--------|----------|-----------------|
| Reproducibility | âœ… Consistent | âŒ Varies |
| Hardware features | âŒ Limited | âœ… Full |
| Kernel | Generic | Vendor-specific |
| TEE/TrustZone | âŒ No | âœ… Yes |
| Baseband/Radio | âŒ No | âœ… Yes |

**Current approach:** Emulators for reproducible training. Physical devices for validation.

---

## Supported Android Versions

Persona configurations exist for:

| Version | API Level | Codename | Persona File |
|---------|-----------|----------|--------------|
| Android 11 | 30 | R | `android_11_user.yaml` |
| Android 14 | 34 | U | `android_14_user.yaml` |
| Android 15 | 35 | V | `android_15_user.yaml` |
| Android 16 | 36 | Baklava | `android_16_user.yaml` |

Each persona includes realistic user data (contacts, SMS, files, apps) to enable meaningful security assessments.

---

## Installation

### Prerequisites

- Python 3.10+
- Android SDK / Platform Tools (ADB)
- Android Emulator or physical device
- Ollama (for local LLM inference)
- MLX / MLX-LM (optional, for Apple Silicon optimization)

### Setup

```bash
# Clone repository
git clone https://github.com/GitSolved/AgenticART.git
cd AgenticART

# Install dependencies
pip install -r requirements.txt

# Install as editable package (optional)
pip install -e .

# Set up environment variables
cp .env.example .env
# Edit .env with your NVD API key (optional, for CVE generation)
```

---

## Usage

### 1. Generate Challenges from NVD

```bash
python3 scripts/generate_nvd_challenges.py
```

Fetches recent Android CVEs and generates challenge templates.

### 2. Run Agent Training

```bash
python3 dojo/test_end_to_end.py --mode live --model <model_name> --belt <target_belt>
```

### 3. Package Training Data

```bash
python3 scripts/package_finetune.py
```

### 4. Fine-tune with MLX (Apple Silicon)

```bash
python3 dojo/custom_train.py
```

---

## Project Structure

```
AgenticART/
â”œâ”€â”€ dojo/
â”‚   â”œâ”€â”€ curriculum/           # Challenge execution engine
â”‚   â”‚   â”œâ”€â”€ white_belt/       # Challenge definitions by belt
â”‚   â”‚   â”œâ”€â”€ yellow_belt/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ black_belt/
â”‚   â”‚   â”œâ”€â”€ challenger.py     # Basic challenge executor
â”‚   â”‚   â”œâ”€â”€ executor.py       # ADB/Frida/C execution engine
â”‚   â”‚   â””â”€â”€ loader.py         # Challenge loading utilities
â”‚   â”œâ”€â”€ sensei/               # Grading and training data pipeline
â”‚   â”‚   â”œâ”€â”€ grader.py         # Output validation and scoring
â”‚   â”‚   â”œâ”€â”€ exporter.py       # Training data export (JSONL/Alpaca)
â”‚   â”‚   â””â”€â”€ sensei.py         # Main orchestrator
â”‚   â”œâ”€â”€ personas/             # Android device configurations
â”‚   â”œâ”€â”€ device/               # Device management and setup
â”‚   â”œâ”€â”€ targets/              # Vulnerable app configurations
â”‚   â”œâ”€â”€ tools/                # NVD generator, utilities
â”‚   â”œâ”€â”€ react_challenger.py   # ReAct (Reason+Act) executor
â”‚   â””â”€â”€ models.py             # Data models (Belt, Challenge, etc.)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_nvd_challenges.py
â”‚   â”œâ”€â”€ package_finetune.py
â”‚   â”œâ”€â”€ evaluate_curriculum.py
â”‚   â””â”€â”€ validate_training_data.py
â”œâ”€â”€ webapp/                   # Streamlit dashboard
â””â”€â”€ tests/
```

---

## Challenge Execution Modes

Challenges specify their execution capability:

| Mode | Description |
|------|-------------|
| `full_execution` | Agent can complete the entire challenge |
| `detection_analysis` | Agent analyzes/detects but cannot exploit |
| `detection_only` | Vulnerability assessment only |
| `simulation` | Simulates behavior patterns |
| `syntax_only` | C code validated locally, not executed |
| `try_harder` | Aspirational challenge with partial credit |

---

## Evaluation Metrics

The framework tracks:

- **Pass Rate:** Percentage of challenges completed successfully
- **Syntax Accuracy:** Valid code generation rate
- **Execution Success:** Commands that run without errors
- **Objective Achievement:** Goal completion rate

---

## Scope & Boundaries

### What AgenticART IS

- âœ… Training framework for Android security assessment agents
- âœ… Curriculum of 192 real-world CVE-based challenges
- âœ… Execution-verified feedback loop for model improvement
- âœ… Realistic non-rooted environment matching real targets
- âœ… Research prototype for studying AI security capabilities

### What AgenticART is NOT

- âŒ Production-ready pentesting tool
- âŒ Zero-day discovery engine (aspirational, not demonstrated)
- âŒ Magic "hack any phone" solution
- âŒ Replacement for human security researchers

### Technical Boundaries

| Capability | Status | Reason |
|------------|--------|--------|
| **Zero-Click Exploits** | Analysis only | Requires months of dedicated 0-day research, memory corruption expertise |
| **Kernel Exploitation** | Detection only | Needs specific kernel builds, not generalizable |
| **Baseband/Radio** | Not supported | Requires physical device with cellular hardware |
| **TrustZone/TEE** | Not supported | Hardware security module not emulated |
| **Bootloader Attacks** | Not supported | Requires unlocked bootloader, physical access |

### Honest Expectations

```
What you SHOULD expect:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Agents that can perform systematic Android reconnaissance
â€¢ Automated vulnerability assessment against known CVEs
â€¢ High-quality training data for security-focused LLMs
â€¢ Foundation for building more advanced security tools

What you should NOT expect:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Agents discovering novel 0-days autonomously
â€¢ "Push button, hack phone" capability
â€¢ Replacement for skilled penetration testers
â€¢ Production-grade security scanner
```

---

## Research Goals

AgenticART explores testable hypotheses:

| Hypothesis | How to Test | Status |
|------------|-------------|--------|
| **Capability Transfer** | Fine-tune 7B model on 70B teacher traces, compare performance | Untested |
| **Execution Verification** | Compare models trained on verified vs unverified data | Untested |
| **Curriculum Learning** | Benchmark before/after belt-progressive training | Untested |
| **Failure Patterns** | Analyze error types across belt levels | Infrastructure exists |

**This framework provides the infrastructure to test these hypotheses, not proven results.**

---

## Contributing

Contributions welcome! Areas of interest:

- Additional CVE challenge templates
- New Android version personas
- Improved grading heuristics
- NDK integration for native execution
- Additional execution domains (e.g., Magisk, Xposed)

---

## License

MIT License - See [LICENSE](LICENSE)

---

## Disclaimer

This framework is for **authorized security research only**. Use only on devices you own or have explicit permission to test. The authors are not responsible for misuse.

---

## Contact

- **Repository:** [github.com/GitSolved/AgenticART](https://github.com/GitSolved/AgenticART)
- **Research Portfolio:** [secureyourgear.com](https://secureyourgear.com)

---

*Last updated: December 30, 2025*
